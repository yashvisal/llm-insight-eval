"""
E2B Data Analysis Tool integration
"""
import os
import asyncio
from typing import Dict, Any, List, Optional
from langchain_community.tools import E2BDataAnalysisTool
from loguru import logger
from .config import get_config

class E2BClient:
    """Client for E2B Data Analysis Tool"""
    
    def __init__(self):
        self.config = get_config()
        self.tool = None
        self.dataset_path = None
        self._initialize_tool()
    
    def _initialize_tool(self):
        """Initialize the E2B Data Analysis Tool"""
        try:
            if not self.config.e2b.enabled:
                logger.warning("E2B is disabled in configuration")
                return
            
            if not self.config.e2b.api_key:
                logger.warning("E2B API key not provided, E2B will not be available")
                return
            
            # Set environment variable
            os.environ["E2B_API_KEY"] = self.config.e2b.api_key
            
            # Initialize the tool with callbacks
            self.tool = E2BDataAnalysisTool(
                on_stdout=lambda stdout: logger.info(f"E2B stdout: {stdout}"),
                on_stderr=lambda stderr: logger.warning(f"E2B stderr: {stderr}"),
                on_artifact=self._handle_artifact,
                timeout=self.config.e2b.timeout
            )
            
            logger.info("E2B Data Analysis Tool initialized successfully")
            
        except Exception as e:
            logger.error(f"Failed to initialize E2B tool: {str(e)}")
            self.tool = None
    
    def _handle_artifact(self, artifact):
        """Handle artifacts (charts, files) generated by E2B"""
        try:
            logger.info(f"New artifact generated: {artifact.name}")
            # Download the artifact
            file_content = artifact.download()
            
            # Save to local directory
            output_dir = "outputs/artifacts"
            os.makedirs(output_dir, exist_ok=True)
            
            file_path = os.path.join(output_dir, artifact.name)
            with open(file_path, "wb") as f:
                f.write(file_content)
            
            logger.info(f"Artifact saved to: {file_path}")
            
        except Exception as e:
            logger.error(f"Error handling artifact: {str(e)}")
    
    async def upload_dataset(self, dataset_path: str) -> Optional[str]:
        """Upload dataset to E2B sandbox"""
        if not self.tool:
            logger.warning("E2B tool not available")
            return None
        
        try:
            with open(dataset_path, "rb") as f:
                remote_path = self.tool.upload_file(
                    file=f,
                    description="Big Mart Sales dataset for analysis"
                )
            
            self.dataset_path = remote_path
            logger.info(f"Dataset uploaded to E2B: {remote_path}")
            return remote_path
            
        except Exception as e:
            logger.error(f"Error uploading dataset: {str(e)}")
            return None
    
    async def install_packages(self, packages: List[str]) -> bool:
        """Install Python packages in E2B sandbox"""
        if not self.tool:
            return False
        
        try:
            for package in packages:
                self.tool.install_python_packages(package)
                logger.info(f"Installed package: {package}")
            return True
            
        except Exception as e:
            logger.error(f"Error installing packages: {str(e)}")
            return False
    
    async def analyze_claim(self, claim: str, dataset_summary: str) -> List[Dict[str, Any]]:
        """Analyze a claim using E2B Data Analysis Tool"""
        if not self.tool:
            logger.warning("E2B tool not available, falling back to basic analysis")
            return []
        
        try:
            # Install required packages
            await self.install_packages(self.config.e2b.auto_install_packages)
            
            # Create analysis prompt
            analysis_prompt = self._create_analysis_prompt(claim, dataset_summary)
            
            # Execute analysis using E2B tool
            result = await self._execute_analysis_with_e2b(analysis_prompt)
            
            return result
            
        except Exception as e:
            logger.error(f"Error in E2B analysis: {str(e)}")
            return []
    
    def _create_analysis_prompt(self, claim: str, dataset_summary: str) -> str:
        """Create a prompt for data analysis"""
        return f"""
You are a data analyst. Analyze the following claim using the Big Mart Sales dataset.

Claim: {claim}
Dataset Summary: {dataset_summary}

Please perform the following analysis:

1. Load the dataset from '{self.dataset_path}'
2. Explore the data to understand its structure
3. Perform relevant statistical analysis to validate or refute the claim
4. Create visualizations if helpful
5. Provide clear conclusions about the claim

Focus on:
- Data quality and completeness
- Statistical significance of findings
- Clear evidence for or against the claim
- Practical implications

Return your analysis as Python code that can be executed in the sandbox.
"""
    
    async def _execute_analysis_with_e2b(self, prompt: str) -> List[Dict[str, Any]]:
        """Execute analysis using E2B tool"""
        try:
            # Use the E2B tool to execute the analysis
            tool_result = await self.tool.ainvoke({
                "python_code": self._generate_analysis_code(prompt)
            })
            
            # Parse the results
            results = []
            
            # Extract stdout and stderr
            if hasattr(tool_result, 'get'):
                stdout = tool_result.get('stdout', '')
                stderr = tool_result.get('stderr', '')
                
                results.append({
                    "analysis_type": "data_analysis",
                    "results": {
                        "stdout": stdout,
                        "stderr": stderr,
                        "success": not stderr
                    },
                    "code_executed": self._generate_analysis_code(prompt),
                    "execution_time": 0.0,  # E2B doesn't provide this directly
                    "success": not stderr,
                    "error_message": stderr if stderr else None
                })
            
            return results
            
        except Exception as e:
            logger.error(f"Error executing analysis with E2B: {str(e)}")
            return [{
                "analysis_type": "data_analysis",
                "results": {},
                "code_executed": "",
                "execution_time": 0.0,
                "success": False,
                "error_message": str(e)
            }]
    
    def _generate_analysis_code(self, prompt: str) -> str:
        """Generate Python code for analysis based on the prompt"""
        # This is a simplified version - in practice, you might want to use an LLM
        # to generate the actual analysis code based on the prompt
        
        return f"""
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats

# Load the dataset
print("Loading Big Mart Sales dataset...")
df = pd.read_csv('{self.dataset_path}')
print(f"Dataset shape: {{df.shape}}")
print(f"Columns: {{list(df.columns)}}")

# Basic data exploration
print("\\n=== Basic Data Exploration ===")
print(df.info())
print("\\nFirst few rows:")
print(df.head())

print("\\n=== Statistical Summary ===")
print(df.describe())

# Check for missing values
print("\\n=== Missing Values ===")
missing_values = df.isnull().sum()
print(missing_values[missing_values > 0])

# Create some basic visualizations
print("\\n=== Creating Visualizations ===")

# Sales distribution
plt.figure(figsize=(10, 6))
plt.subplot(2, 2, 1)
df['Item_Outlet_Sales'].hist(bins=50)
plt.title('Distribution of Sales')
plt.xlabel('Sales')
plt.ylabel('Frequency')

# Sales by outlet type
plt.subplot(2, 2, 2)
df.groupby('Outlet_Type')['Item_Outlet_Sales'].mean().plot(kind='bar')
plt.title('Average Sales by Outlet Type')
plt.xticks(rotation=45)

# Sales by item type
plt.subplot(2, 2, 3)
df.groupby('Item_Type')['Item_Outlet_Sales'].mean().plot(kind='bar')
plt.title('Average Sales by Item Type')
plt.xticks(rotation=45)

# Correlation heatmap for numerical columns
plt.subplot(2, 2, 4)
numerical_cols = df.select_dtypes(include=[np.number]).columns
correlation_matrix = df[numerical_cols].corr()
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)
plt.title('Correlation Matrix')

plt.tight_layout()
plt.savefig('/home/user/sales_analysis.png')
plt.show()

print("\\n=== Analysis Complete ===")
print("The analysis has been completed and visualizations saved.")
""" 